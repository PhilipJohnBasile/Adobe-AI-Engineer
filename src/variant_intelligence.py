"""
AI-Powered Variant Intelligence System
Advanced tracking with quality analysis, diversity metrics, and brand compliance
"""

import asyncio
import json
import os
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from pathlib import Path
import numpy as np
from PIL import Image
import cv2
import logging
import hashlib
from collections import defaultdict
import openai

@dataclass
class VariantMetrics:
    """Comprehensive variant metrics with AI analysis"""
    total_count: int = 0
    unique_count: int = 0
    duplicate_count: int = 0
    
    # Quality metrics
    avg_quality_score: float = 0.0
    quality_distribution: Dict[str, int] = field(default_factory=dict)
    technical_quality: Dict[str, float] = field(default_factory=dict)
    
    # Diversity analysis
    diversity_index: float = 0.0
    style_variety_score: float = 0.0
    color_diversity: float = 0.0
    composition_diversity: float = 0.0
    content_diversity: float = 0.0
    
    # Brand compliance
    brand_compliance_rate: float = 0.0
    guideline_violations: List[str] = field(default_factory=list)
    brand_consistency_score: float = 0.0
    
    # Performance metrics
    avg_generation_time: float = 0.0
    success_rate: float = 0.0
    retry_rate: float = 0.0
    cost_per_variant: float = 0.0
    
    # Engagement predictions
    predicted_engagement: Dict[str, float] = field(default_factory=dict)
    A_B_test_recommendations: List[str] = field(default_factory=list)

@dataclass
class VariantAnalysis:
    """Individual variant analysis results"""
    variant_id: str
    file_path: str
    file_hash: str
    
    # Technical properties
    resolution: Tuple[int, int]
    aspect_ratio: str
    file_size: int
    format: str
    
    # Quality scores
    technical_quality: float = 0.0
    aesthetic_quality: float = 0.0
    brand_alignment: float = 0.0
    content_relevance: float = 0.0
    
    # Visual analysis
    dominant_colors: List[str] = field(default_factory=list)
    composition_type: str = ""
    text_elements: List[str] = field(default_factory=list)
    object_detection: List[str] = field(default_factory=list)
    
    # Brand compliance
    brand_colors_present: bool = False
    logo_detected: bool = False
    font_compliance: bool = False
    style_compliance: bool = False
    
    # Issues and recommendations
    detected_issues: List[str] = field(default_factory=list)
    improvement_suggestions: List[str] = field(default_factory=list)
    
    # Metadata
    created_at: datetime = field(default_factory=datetime.now)
    processing_time: float = 0.0

class VariantIntelligenceEngine:
    """AI-powered variant tracking and analysis system"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # AI models and analyzers
        self.quality_analyzer = QualityAnalyzer()
        self.diversity_analyzer = DiversityAnalyzer()
        self.brand_analyzer = BrandComplianceAnalyzer()
        self.performance_tracker = PerformanceTracker()
        self.engagement_predictor = EngagementPredictor()
        
        # Variant tracking state
        self.variant_database = {}
        self.campaign_metrics = {}
        self.analysis_cache = {}
        
        # Configuration
        self.config = {
            "quality_threshold": 0.7,
            "diversity_threshold": 0.6,
            "brand_compliance_threshold": 0.85,
            "auto_analysis": True,
            "real_time_tracking": True,
            "duplicate_detection": True,
            "engagement_prediction": True,
            "advanced_computer_vision": True
        }
        
        # Initialize AI services
        self._initialize_ai_services()
    
    def _initialize_ai_services(self):
        """Initialize AI services for variant analysis"""
        self.openai_client = None
        if os.getenv("OPENAI_API_KEY"):
            try:
                from openai import OpenAI
                self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                self.logger.info("‚úÖ OpenAI client initialized for variant analysis")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è OpenAI initialization failed: {e}")
    
    async def track_campaign_variants(self, campaign_id: str, output_dir: Path) -> VariantMetrics:
        """Comprehensive variant tracking for a campaign"""
        
        self.logger.info(f"üìä Starting comprehensive variant analysis for campaign: {campaign_id}")
        start_time = time.time()
        
        # Discover all variants
        variant_files = await self._discover_variants(output_dir, campaign_id)
        
        if not variant_files:
            self.logger.warning(f"‚ö†Ô∏è No variants found for campaign {campaign_id}")
            return VariantMetrics()
        
        # Analyze each variant
        variant_analyses = []
        for variant_file in variant_files:
            analysis = await self._analyze_single_variant(variant_file, campaign_id)
            if analysis:
                variant_analyses.append(analysis)
        
        # Calculate comprehensive metrics
        metrics = await self._calculate_comprehensive_metrics(variant_analyses, campaign_id)
        
        # Store results
        self.campaign_metrics[campaign_id] = metrics
        
        processing_time = time.time() - start_time
        self.logger.info(f"‚úÖ Variant analysis completed in {processing_time:.2f}s: {metrics.total_count} variants")
        
        return metrics
    
    async def _discover_variants(self, output_dir: Path, campaign_id: str) -> List[Path]:
        """Discover all variant files for a campaign"""
        
        variant_files = []
        campaign_path = output_dir / campaign_id
        
        if not campaign_path.exists():
            return variant_files
        
        # Supported image formats
        image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.tiff', '.bmp'}
        
        # Recursively find all image files
        for file_path in campaign_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in image_extensions:
                variant_files.append(file_path)
        
        self.logger.info(f"üîç Discovered {len(variant_files)} variant files for {campaign_id}")
        return variant_files
    
    async def _analyze_single_variant(self, variant_file: Path, campaign_id: str) -> Optional[VariantAnalysis]:
        """Comprehensive analysis of a single variant"""
        
        try:
            start_time = time.time()
            
            # Basic file analysis
            file_stats = variant_file.stat()
            file_hash = self._calculate_file_hash(variant_file)
            
            # Check cache first
            if file_hash in self.analysis_cache:
                return self.analysis_cache[file_hash]
            
            # Create analysis object
            analysis = VariantAnalysis(
                variant_id=f"{campaign_id}_{variant_file.stem}",
                file_path=str(variant_file),
                file_hash=file_hash,
                resolution=(0, 0),
                aspect_ratio="unknown",
                file_size=file_stats.st_size,
                format=variant_file.suffix.lower()
            )
            
            # Load and analyze image
            try:
                image = Image.open(variant_file)
                analysis.resolution = image.size
                analysis.aspect_ratio = self._calculate_aspect_ratio(image.size)
                
                # Quality analysis
                analysis.technical_quality = await self.quality_analyzer.analyze_technical_quality(image)
                analysis.aesthetic_quality = await self.quality_analyzer.analyze_aesthetic_quality(image)
                
                # Visual analysis
                analysis.dominant_colors = await self._extract_dominant_colors(image)
                analysis.composition_type = await self._analyze_composition(image)
                analysis.object_detection = await self._detect_objects(image)
                
                # Brand compliance analysis
                brand_results = await self.brand_analyzer.analyze_compliance(image, campaign_id)
                analysis.brand_alignment = brand_results["alignment_score"]
                analysis.brand_colors_present = brand_results["colors_compliant"]
                analysis.logo_detected = brand_results["logo_detected"]
                analysis.font_compliance = brand_results["font_compliant"]
                analysis.style_compliance = brand_results["style_compliant"]
                
                # Content analysis with AI
                if self.openai_client:
                    content_analysis = await self._ai_content_analysis(image, variant_file)
                    analysis.content_relevance = content_analysis.get("relevance_score", 0.5)
                    analysis.text_elements = content_analysis.get("text_elements", [])
                    analysis.improvement_suggestions = content_analysis.get("suggestions", [])
                
                # Issue detection
                analysis.detected_issues = await self._detect_issues(analysis)
                
                image.close()
                
            except Exception as e:
                self.logger.error(f"‚ùå Error analyzing image {variant_file}: {e}")
                analysis.detected_issues.append(f"Image analysis failed: {str(e)}")
            
            analysis.processing_time = time.time() - start_time
            
            # Cache the analysis
            self.analysis_cache[file_hash] = analysis
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"‚ùå Error in variant analysis for {variant_file}: {e}")
            return None
    
    async def _calculate_comprehensive_metrics(self, analyses: List[VariantAnalysis], campaign_id: str) -> VariantMetrics:
        """Calculate comprehensive metrics from variant analyses"""
        
        if not analyses:
            return VariantMetrics()
        
        metrics = VariantMetrics()
        
        # Basic counts
        metrics.total_count = len(analyses)
        unique_hashes = set(analysis.file_hash for analysis in analyses)
        metrics.unique_count = len(unique_hashes)
        metrics.duplicate_count = metrics.total_count - metrics.unique_count
        
        # Quality metrics
        quality_scores = [analysis.technical_quality for analysis in analyses if analysis.technical_quality > 0]
        if quality_scores:
            metrics.avg_quality_score = np.mean(quality_scores)
            metrics.quality_distribution = self._calculate_quality_distribution(quality_scores)
        
        # Technical quality breakdown
        metrics.technical_quality = {
            "resolution": np.mean([self._score_resolution(analysis.resolution) for analysis in analyses]),
            "file_size": np.mean([self._score_file_size(analysis.file_size) for analysis in analyses]),
            "format_optimization": np.mean([self._score_format(analysis.format) for analysis in analyses])
        }
        
        # Diversity analysis
        metrics.diversity_index = await self.diversity_analyzer.calculate_diversity_index(analyses)
        metrics.style_variety_score = await self.diversity_analyzer.calculate_style_variety(analyses)
        metrics.color_diversity = await self.diversity_analyzer.calculate_color_diversity(analyses)
        metrics.composition_diversity = await self.diversity_analyzer.calculate_composition_diversity(analyses)
        metrics.content_diversity = await self.diversity_analyzer.calculate_content_diversity(analyses)
        
        # Brand compliance
        compliance_scores = [analysis.brand_alignment for analysis in analyses if analysis.brand_alignment > 0]
        if compliance_scores:
            metrics.brand_compliance_rate = np.mean(compliance_scores)
        
        brand_violations = []
        for analysis in analyses:
            if not analysis.brand_colors_present:
                brand_violations.append(f"Brand colors missing in {analysis.variant_id}")
            if not analysis.logo_detected and "logo_required" in self.config:
                brand_violations.append(f"Logo missing in {analysis.variant_id}")
        
        metrics.guideline_violations = brand_violations
        metrics.brand_consistency_score = await self._calculate_brand_consistency(analyses)
        
        # Performance metrics
        processing_times = [analysis.processing_time for analysis in analyses if analysis.processing_time > 0]
        if processing_times:
            metrics.avg_generation_time = np.mean(processing_times)
        
        # Calculate success rate based on quality thresholds
        successful_variants = len([a for a in analyses if a.technical_quality >= self.config["quality_threshold"]])
        metrics.success_rate = successful_variants / len(analyses) if analyses else 0
        
        # Cost estimation
        metrics.cost_per_variant = await self._estimate_cost_per_variant(analyses)
        
        # Engagement predictions
        if self.config["engagement_prediction"]:
            metrics.predicted_engagement = await self.engagement_predictor.predict_engagement(analyses)
            metrics.A_B_test_recommendations = await self.engagement_predictor.generate_ab_test_recommendations(analyses)
        
        return metrics
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """Calculate hash for duplicate detection"""
        hasher = hashlib.md5()
        try:
            with open(file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hasher.update(chunk)
            return hasher.hexdigest()
        except:
            return f"error_{file_path.name}_{time.time()}"
    
    def _calculate_aspect_ratio(self, size: Tuple[int, int]) -> str:
        """Calculate and classify aspect ratio"""
        width, height = size
        ratio = width / height
        
        if abs(ratio - 1.0) < 0.1:
            return "1:1"
        elif abs(ratio - 16/9) < 0.1:
            return "16:9"
        elif abs(ratio - 9/16) < 0.1:
            return "9:16"
        elif abs(ratio - 4/3) < 0.1:
            return "4:3"
        elif abs(ratio - 3/4) < 0.1:
            return "3:4"
        else:
            return f"{width}:{height}"
    
    async def _extract_dominant_colors(self, image: Image) -> List[str]:
        """Extract dominant colors from image"""
        try:
            # Convert to RGB if needed
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Resize for faster processing
            image_small = image.resize((150, 150))
            
            # Convert to numpy array
            img_array = np.array(image_small)
            
            # Reshape to list of pixels
            pixels = img_array.reshape(-1, 3)
            
            # Use simple clustering to find dominant colors
            # In production, you'd use scikit-learn's KMeans
            unique_colors = []
            for pixel in pixels[::100]:  # Sample every 100th pixel
                color_hex = f"#{pixel[0]:02x}{pixel[1]:02x}{pixel[2]:02x}"
                if color_hex not in unique_colors and len(unique_colors) < 5:
                    unique_colors.append(color_hex)
            
            return unique_colors
            
        except Exception as e:
            self.logger.error(f"Error extracting colors: {e}")
            return []
    
    async def _analyze_composition(self, image: Image) -> str:
        """Analyze image composition type"""
        try:
            width, height = image.size
            aspect_ratio = width / height
            
            # Simple composition analysis
            if aspect_ratio > 1.5:
                return "landscape"
            elif aspect_ratio < 0.7:
                return "portrait"
            else:
                return "square"
                
        except:
            return "unknown"
    
    async def _detect_objects(self, image: Image) -> List[str]:
        """Detect objects in image (placeholder for actual CV model)"""
        # In production, this would use a real object detection model
        # like YOLO, TensorFlow Object Detection, or cloud vision APIs
        
        # Placeholder implementation
        width, height = image.size
        file_size = len(image.tobytes()) if hasattr(image, 'tobytes') else 0
        
        detected_objects = []
        
        # Simple heuristics (replace with actual CV model)
        if width > 800 and height > 800:
            detected_objects.append("high_resolution_content")
        
        if file_size > 1000000:  # > 1MB
            detected_objects.append("detailed_imagery")
        
        return detected_objects
    
    async def _ai_content_analysis(self, image: Image, variant_file: Path) -> Dict[str, Any]:
        """AI-powered content analysis using vision models"""
        try:
            # This would integrate with vision models like GPT-4V, Claude Vision, etc.
            # For now, returning mock analysis
            
            analysis = {
                "relevance_score": 0.8,
                "text_elements": [],
                "suggestions": [
                    "Consider improving text readability",
                    "Enhance color contrast for better accessibility",
                    "Optimize composition for better visual flow"
                ]
            }
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"AI content analysis failed: {e}")
            return {"relevance_score": 0.5, "text_elements": [], "suggestions": []}
    
    async def _detect_issues(self, analysis: VariantAnalysis) -> List[str]:
        """Detect potential issues with the variant"""
        issues = []
        
        # Quality issues
        if analysis.technical_quality < self.config["quality_threshold"]:
            issues.append("Low technical quality")
        
        # Resolution issues
        if analysis.resolution[0] < 800 or analysis.resolution[1] < 800:
            issues.append("Low resolution")
        
        # Brand compliance issues
        if not analysis.brand_colors_present:
            issues.append("Brand colors not detected")
        
        if analysis.brand_alignment < self.config["brand_compliance_threshold"]:
            issues.append("Poor brand alignment")
        
        # File size issues
        if analysis.file_size > 5 * 1024 * 1024:  # > 5MB
            issues.append("File size too large")
        elif analysis.file_size < 50 * 1024:  # < 50KB
            issues.append("File size suspiciously small")
        
        return issues


class QualityAnalyzer:
    """Advanced quality analysis for variants"""
    
    async def analyze_technical_quality(self, image: Image) -> float:
        """Analyze technical quality of image"""
        try:
            # Convert to OpenCV format for analysis
            img_array = np.array(image)
            
            # Calculate sharpness using Laplacian variance
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) if len(img_array.shape) == 3 else img_array
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # Normalize sharpness score
            sharpness_score = min(sharpness / 1000, 1.0)
            
            # Calculate noise level (simplified)
            noise_score = 1.0 - min(np.std(gray) / 128, 1.0)
            
            # Combine metrics
            technical_score = (sharpness_score * 0.6 + noise_score * 0.4)
            
            return min(max(technical_score, 0.0), 1.0)
            
        except Exception as e:
            logging.getLogger(__name__).error(f"Technical quality analysis failed: {e}")
            return 0.5
    
    async def analyze_aesthetic_quality(self, image: Image) -> float:
        """Analyze aesthetic quality (placeholder for advanced models)"""
        try:
            # This would integrate with aesthetic quality models
            # For now, using simple heuristics
            
            width, height = image.size
            aspect_ratio = width / height
            
            # Prefer common aspect ratios
            common_ratios = [1.0, 16/9, 9/16, 4/3, 3/4]
            ratio_score = max([1 - abs(aspect_ratio - ratio) for ratio in common_ratios])
            
            # Prefer higher resolutions
            resolution_score = min((width * height) / (1920 * 1080), 1.0)
            
            aesthetic_score = (ratio_score * 0.4 + resolution_score * 0.6)
            
            return min(max(aesthetic_score, 0.0), 1.0)
            
        except:
            return 0.5


class DiversityAnalyzer:
    """Advanced diversity analysis for variant collections"""
    
    async def calculate_diversity_index(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate overall diversity index"""
        if not analyses:
            return 0.0
        
        # Combine multiple diversity factors
        color_div = await self.calculate_color_diversity(analyses)
        composition_div = await self.calculate_composition_diversity(analyses)
        content_div = await self.calculate_content_diversity(analyses)
        
        return (color_div + composition_div + content_div) / 3
    
    async def calculate_style_variety(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate style variety score"""
        if not analyses:
            return 0.0
        
        # Count unique composition types
        composition_types = set(analysis.composition_type for analysis in analyses)
        
        # Count unique aspect ratios
        aspect_ratios = set(analysis.aspect_ratio for analysis in analyses)
        
        # Calculate variety score
        variety_score = (len(composition_types) + len(aspect_ratios)) / (2 * len(analyses))
        
        return min(variety_score, 1.0)
    
    async def calculate_color_diversity(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate color diversity across variants"""
        if not analyses:
            return 0.0
        
        all_colors = set()
        for analysis in analyses:
            all_colors.update(analysis.dominant_colors)
        
        # Diversity based on unique colors vs total variants
        diversity_score = len(all_colors) / (len(analyses) * 5)  # Assume max 5 colors per variant
        
        return min(diversity_score, 1.0)
    
    async def calculate_composition_diversity(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate composition diversity"""
        if not analyses:
            return 0.0
        
        composition_types = [analysis.composition_type for analysis in analyses]
        unique_compositions = set(composition_types)
        
        diversity_score = len(unique_compositions) / len(analyses)
        
        return min(diversity_score, 1.0)
    
    async def calculate_content_diversity(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate content diversity based on detected objects and elements"""
        if not analyses:
            return 0.0
        
        all_objects = set()
        for analysis in analyses:
            all_objects.update(analysis.object_detection)
            all_objects.update(analysis.text_elements)
        
        diversity_score = len(all_objects) / len(analyses)
        
        return min(diversity_score, 1.0)


class BrandComplianceAnalyzer:
    """Brand compliance analysis and guideline validation"""
    
    async def analyze_compliance(self, image: Image, campaign_id: str) -> Dict[str, Any]:
        """Analyze brand compliance for an image"""
        
        # This would integrate with brand guideline databases
        # For now, using simplified analysis
        
        results = {
            "alignment_score": 0.8,
            "colors_compliant": True,
            "logo_detected": False,
            "font_compliant": True,
            "style_compliant": True,
            "violations": []
        }
        
        # Load brand guidelines for campaign (placeholder)
        brand_guidelines = await self._load_brand_guidelines(campaign_id)
        
        # Analyze brand colors
        results["colors_compliant"] = await self._check_brand_colors(image, brand_guidelines)
        
        # Check for logo presence
        results["logo_detected"] = await self._detect_logo(image, brand_guidelines)
        
        return results
    
    async def _load_brand_guidelines(self, campaign_id: str) -> Dict[str, Any]:
        """Load brand guidelines for campaign"""
        # Placeholder - would load from brand guidelines database
        return {
            "colors": ["#FF0000", "#0000FF", "#FFFFFF"],
            "fonts": ["Arial", "Helvetica"],
            "logo_required": True,
            "style_elements": ["modern", "clean"]
        }
    
    async def _check_brand_colors(self, image: Image, guidelines: Dict[str, Any]) -> bool:
        """Check if brand colors are present"""
        # Simplified color checking
        # Would use advanced color analysis in production
        return True
    
    async def _detect_logo(self, image: Image, guidelines: Dict[str, Any]) -> bool:
        """Detect brand logo in image"""
        # Placeholder for logo detection
        # Would use trained logo detection models
        return False


class PerformanceTracker:
    """Track performance metrics for variant generation"""
    
    def __init__(self):
        self.generation_times = []
        self.success_rates = {}
        self.cost_tracking = {}
    
    def track_generation_time(self, variant_id: str, generation_time: float):
        """Track generation time for a variant"""
        self.generation_times.append({
            "variant_id": variant_id,
            "time": generation_time,
            "timestamp": datetime.now()
        })
    
    def calculate_average_generation_time(self, campaign_id: str) -> float:
        """Calculate average generation time for campaign"""
        campaign_times = [
            entry["time"] for entry in self.generation_times
            if entry["variant_id"].startswith(campaign_id)
        ]
        
        return np.mean(campaign_times) if campaign_times else 0.0


class EngagementPredictor:
    """Predict engagement potential for variants"""
    
    async def predict_engagement(self, analyses: List[VariantAnalysis]) -> Dict[str, float]:
        """Predict engagement metrics for variants"""
        
        predictions = {
            "click_through_rate": 0.0,
            "conversion_rate": 0.0,
            "engagement_score": 0.0,
            "viral_potential": 0.0
        }
        
        if not analyses:
            return predictions
        
        # Calculate predictions based on quality and diversity
        avg_quality = np.mean([a.technical_quality for a in analyses if a.technical_quality > 0])
        
        # Simple prediction model (would use ML in production)
        predictions["click_through_rate"] = min(avg_quality * 0.05, 0.1)
        predictions["conversion_rate"] = min(avg_quality * 0.02, 0.05)
        predictions["engagement_score"] = avg_quality
        predictions["viral_potential"] = avg_quality * 0.3
        
        return predictions
    
    async def generate_ab_test_recommendations(self, analyses: List[VariantAnalysis]) -> List[str]:
        """Generate A/B testing recommendations"""
        
        recommendations = []
        
        if len(analyses) >= 2:
            recommendations.append("Test top 2 performing variants for CTR optimization")
        
        if len(set(a.composition_type for a in analyses)) > 1:
            recommendations.append("A/B test different composition styles")
        
        if len(set(a.aspect_ratio for a in analyses)) > 1:
            recommendations.append("Compare performance across aspect ratios")
        
        return recommendations


# Example usage and demo
async def demo_variant_intelligence():
    """Demonstrate the variant intelligence system"""
    engine = VariantIntelligenceEngine()
    
    print("üé® AI-Powered Variant Intelligence System Demo")
    print("=" * 50)
    print("üìä Advanced Features:")
    print("  ‚úÖ AI-powered quality analysis and scoring")
    print("  ‚úÖ Comprehensive diversity and variety metrics")
    print("  ‚úÖ Brand compliance and guideline validation")
    print("  ‚úÖ Performance tracking and optimization insights")
    print("  ‚úÖ Engagement prediction and A/B test recommendations")
    print("  ‚úÖ Real-time duplicate detection and issue identification")
    
    # Simulate variant tracking
    output_dir = Path("output")
    campaign_id = "demo_campaign"
    
    print(f"\nüîç Analyzing variants for campaign: {campaign_id}")
    
    # This would analyze real variants in production
    metrics = await engine.track_campaign_variants(campaign_id, output_dir)
    
    print(f"üìà Analysis Results:")
    print(f"  Total Variants: {metrics.total_count}")
    print(f"  Quality Score: {metrics.avg_quality_score:.2f}")
    print(f"  Diversity Index: {metrics.diversity_index:.2f}")
    print(f"  Brand Compliance: {metrics.brand_compliance_rate:.2f}")
    
    return engine


if __name__ == "__main__":
    asyncio.run(demo_variant_intelligence())