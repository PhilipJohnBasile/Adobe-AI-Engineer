"""
AI-Powered Variant Intelligence System
Advanced tracking with quality analysis, diversity metrics, and brand compliance
"""

import asyncio
import json
import os
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from pathlib import Path
import numpy as np
from PIL import Image
import cv2
import logging
import hashlib
from collections import defaultdict
import openai

@dataclass
class VariantMetrics:
    """Comprehensive variant metrics with AI analysis"""
    total_count: int = 0
    unique_count: int = 0
    duplicate_count: int = 0
    
    # Quality metrics
    avg_quality_score: float = 0.0
    quality_distribution: Dict[str, int] = field(default_factory=dict)
    technical_quality: Dict[str, float] = field(default_factory=dict)
    
    # Diversity analysis
    diversity_index: float = 0.0
    style_variety_score: float = 0.0
    color_diversity: float = 0.0
    composition_diversity: float = 0.0
    content_diversity: float = 0.0
    
    # Brand compliance
    brand_compliance_rate: float = 0.0
    guideline_violations: List[str] = field(default_factory=list)
    brand_consistency_score: float = 0.0
    
    # Performance metrics
    avg_generation_time: float = 0.0
    success_rate: float = 0.0
    retry_rate: float = 0.0
    cost_per_variant: float = 0.0
    
    # Engagement predictions
    predicted_engagement: Dict[str, float] = field(default_factory=dict)
    A_B_test_recommendations: List[str] = field(default_factory=list)

@dataclass
class VariantAnalysis:
    """Individual variant analysis results"""
    variant_id: str
    file_path: str
    file_hash: str
    
    # Technical properties
    resolution: Tuple[int, int]
    aspect_ratio: str
    file_size: int
    format: str
    
    # Quality scores
    technical_quality: float = 0.0
    aesthetic_quality: float = 0.0
    brand_alignment: float = 0.0
    content_relevance: float = 0.0
    
    # Visual analysis
    dominant_colors: List[str] = field(default_factory=list)
    composition_type: str = ""
    text_elements: List[str] = field(default_factory=list)
    object_detection: List[str] = field(default_factory=list)
    
    # Brand compliance
    brand_colors_present: bool = False
    logo_detected: bool = False
    font_compliance: bool = False
    style_compliance: bool = False
    
    # Issues and recommendations
    detected_issues: List[str] = field(default_factory=list)
    improvement_suggestions: List[str] = field(default_factory=list)
    
    # Metadata
    created_at: datetime = field(default_factory=datetime.now)
    processing_time: float = 0.0

class VariantIntelligenceEngine:
    """AI-powered variant tracking and analysis system"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # AI models and analyzers
        self.quality_analyzer = QualityAnalyzer()
        self.diversity_analyzer = DiversityAnalyzer()
        self.brand_analyzer = BrandComplianceAnalyzer()
        self.performance_tracker = PerformanceTracker()
        self.engagement_predictor = EngagementPredictor()
        
        # Variant tracking state
        self.variant_database = {}
        self.campaign_metrics = {}
        self.analysis_cache = {}
        
        # Configuration
        self.config = {
            "quality_threshold": 0.7,
            "diversity_threshold": 0.6,
            "brand_compliance_threshold": 0.85,
            "auto_analysis": True,
            "real_time_tracking": True,
            "duplicate_detection": True,
            "engagement_prediction": True,
            "advanced_computer_vision": True
        }
        
        # Initialize AI services
        self._initialize_ai_services()
    
    def _initialize_ai_services(self):
        """Initialize AI services for variant analysis"""
        self.openai_client = None
        if os.getenv("OPENAI_API_KEY"):
            try:
                from openai import OpenAI
                self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                self.logger.info("‚úÖ OpenAI client initialized for variant analysis")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è OpenAI initialization failed: {e}")
    
    async def track_campaign_variants(self, campaign_id: str, output_dir: Path) -> VariantMetrics:
        """Comprehensive variant tracking for a campaign"""
        
        self.logger.info(f"üìä Starting comprehensive variant analysis for campaign: {campaign_id}")
        start_time = time.time()
        
        # Discover all variants
        variant_files = await self._discover_variants(output_dir, campaign_id)
        
        if not variant_files:
            self.logger.warning(f"‚ö†Ô∏è No variants found for campaign {campaign_id}")
            return VariantMetrics()
        
        # Analyze each variant
        variant_analyses = []
        for variant_file in variant_files:
            analysis = await self._analyze_single_variant(variant_file, campaign_id)
            if analysis:
                variant_analyses.append(analysis)
        
        # Calculate comprehensive metrics
        metrics = await self._calculate_comprehensive_metrics(variant_analyses, campaign_id)
        
        # Store results
        self.campaign_metrics[campaign_id] = metrics
        
        processing_time = time.time() - start_time
        self.logger.info(f"‚úÖ Variant analysis completed in {processing_time:.2f}s: {metrics.total_count} variants")
        
        return metrics
    
    async def _discover_variants(self, output_dir: Path, campaign_id: str) -> List[Path]:
        """Discover all variant files for a campaign"""
        
        variant_files = []
        campaign_path = output_dir / campaign_id
        
        if not campaign_path.exists():
            return variant_files
        
        # Supported image formats
        image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.tiff', '.bmp'}
        
        # Recursively find all image files
        for file_path in campaign_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in image_extensions:
                variant_files.append(file_path)
        
        self.logger.info(f"üîç Discovered {len(variant_files)} variant files for {campaign_id}")
        return variant_files
    
    async def _analyze_single_variant(self, variant_file: Path, campaign_id: str) -> Optional[VariantAnalysis]:
        """Comprehensive analysis of a single variant"""
        
        try:
            start_time = time.time()
            
            # Basic file analysis
            file_stats = variant_file.stat()
            file_hash = self._calculate_file_hash(variant_file)
            
            # Check cache first
            if file_hash in self.analysis_cache:
                return self.analysis_cache[file_hash]
            
            # Create analysis object
            analysis = VariantAnalysis(
                variant_id=f"{campaign_id}_{variant_file.stem}",
                file_path=str(variant_file),
                file_hash=file_hash,
                resolution=(0, 0),
                aspect_ratio="unknown",
                file_size=file_stats.st_size,
                format=variant_file.suffix.lower()
            )
            
            # Load and analyze image
            try:
                image = Image.open(variant_file)
                analysis.resolution = image.size
                analysis.aspect_ratio = self._calculate_aspect_ratio(image.size)
                
                # Quality analysis
                analysis.technical_quality = await self.quality_analyzer.analyze_technical_quality(image)
                analysis.aesthetic_quality = await self.quality_analyzer.analyze_aesthetic_quality(image)
                
                # Visual analysis
                analysis.dominant_colors = await self._extract_dominant_colors(image)
                analysis.composition_type = await self._analyze_composition(image)
                analysis.object_detection = await self._detect_objects(image)
                
                # Brand compliance analysis
                brand_results = await self.brand_analyzer.analyze_compliance(image, campaign_id)
                analysis.brand_alignment = brand_results["alignment_score"]
                analysis.brand_colors_present = brand_results["colors_compliant"]
                analysis.logo_detected = brand_results["logo_detected"]
                analysis.font_compliance = brand_results["font_compliant"]
                analysis.style_compliance = brand_results["style_compliant"]
                
                # Content analysis with AI
                if self.openai_client:
                    content_analysis = await self._ai_content_analysis(image, variant_file)
                    analysis.content_relevance = content_analysis.get("relevance_score", 0.5)
                    analysis.text_elements = content_analysis.get("text_elements", [])
                    analysis.improvement_suggestions = content_analysis.get("suggestions", [])
                
                # Issue detection
                analysis.detected_issues = await self._detect_issues(analysis)
                
                image.close()
                
            except Exception as e:
                self.logger.error(f"‚ùå Error analyzing image {variant_file}: {e}")
                analysis.detected_issues.append(f"Image analysis failed: {str(e)}")
            
            analysis.processing_time = time.time() - start_time
            
            # Cache the analysis
            self.analysis_cache[file_hash] = analysis
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"‚ùå Error in variant analysis for {variant_file}: {e}")
            return None
    
    async def _calculate_comprehensive_metrics(self, analyses: List[VariantAnalysis], campaign_id: str) -> VariantMetrics:
        """Calculate comprehensive metrics from variant analyses"""
        
        if not analyses:
            return VariantMetrics()
        
        metrics = VariantMetrics()
        
        # Basic counts
        metrics.total_count = len(analyses)
        unique_hashes = set(analysis.file_hash for analysis in analyses)
        metrics.unique_count = len(unique_hashes)
        metrics.duplicate_count = metrics.total_count - metrics.unique_count
        
        # Quality metrics
        quality_scores = [analysis.technical_quality for analysis in analyses if analysis.technical_quality > 0]
        if quality_scores:
            metrics.avg_quality_score = np.mean(quality_scores)
            metrics.quality_distribution = self._calculate_quality_distribution(quality_scores)
        
        # Technical quality breakdown
        metrics.technical_quality = {
            "resolution": np.mean([self._score_resolution(analysis.resolution) for analysis in analyses]),
            "file_size": np.mean([self._score_file_size(analysis.file_size) for analysis in analyses]),
            "format_optimization": np.mean([self._score_format(analysis.format) for analysis in analyses])
        }
        
        # Diversity analysis
        metrics.diversity_index = await self.diversity_analyzer.calculate_diversity_index(analyses)
        metrics.style_variety_score = await self.diversity_analyzer.calculate_style_variety(analyses)
        metrics.color_diversity = await self.diversity_analyzer.calculate_color_diversity(analyses)
        metrics.composition_diversity = await self.diversity_analyzer.calculate_composition_diversity(analyses)
        metrics.content_diversity = await self.diversity_analyzer.calculate_content_diversity(analyses)
        
        # Brand compliance
        compliance_scores = [analysis.brand_alignment for analysis in analyses if analysis.brand_alignment > 0]
        if compliance_scores:
            metrics.brand_compliance_rate = np.mean(compliance_scores)
        
        brand_violations = []
        for analysis in analyses:
            if not analysis.brand_colors_present:
                brand_violations.append(f"Brand colors missing in {analysis.variant_id}")
            if not analysis.logo_detected and "logo_required" in self.config:
                brand_violations.append(f"Logo missing in {analysis.variant_id}")
        
        metrics.guideline_violations = brand_violations
        metrics.brand_consistency_score = await self._calculate_brand_consistency(analyses)
        
        # Performance metrics
        processing_times = [analysis.processing_time for analysis in analyses if analysis.processing_time > 0]
        if processing_times:
            metrics.avg_generation_time = np.mean(processing_times)
        
        # Calculate success rate based on quality thresholds
        successful_variants = len([a for a in analyses if a.technical_quality >= self.config["quality_threshold"]])
        metrics.success_rate = successful_variants / len(analyses) if analyses else 0
        
        # Cost estimation
        metrics.cost_per_variant = await self._estimate_cost_per_variant(analyses)
        
        # Engagement predictions
        if self.config["engagement_prediction"]:
            metrics.predicted_engagement = await self.engagement_predictor.predict_engagement(analyses)
            metrics.A_B_test_recommendations = await self.engagement_predictor.generate_ab_test_recommendations(analyses)
        
        return metrics
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """Calculate hash for duplicate detection"""
        hasher = hashlib.md5()
        try:
            with open(file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hasher.update(chunk)
            return hasher.hexdigest()
        except (OSError, IOError):
            return f"error_{file_path.name}_{time.time()}"
    
    def _calculate_aspect_ratio(self, size: Tuple[int, int]) -> str:
        """Calculate and classify aspect ratio"""
        width, height = size
        ratio = width / height
        
        if abs(ratio - 1.0) < 0.1:
            return "1:1"
        elif abs(ratio - 16/9) < 0.1:
            return "16:9"
        elif abs(ratio - 9/16) < 0.1:
            return "9:16"
        elif abs(ratio - 4/3) < 0.1:
            return "4:3"
        elif abs(ratio - 3/4) < 0.1:
            return "3:4"
        else:
            return f"{width}:{height}"
    
    async def _extract_dominant_colors(self, image: Image) -> List[str]:
        """Extract dominant colors from image"""
        try:
            # Convert to RGB if needed
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Resize for faster processing
            image_small = image.resize((150, 150))
            
            # Convert to numpy array
            img_array = np.array(image_small)
            
            # Reshape to list of pixels
            pixels = img_array.reshape(-1, 3)
            
            # Use simple clustering to find dominant colors
            # In production, you'd use scikit-learn's KMeans
            unique_colors = []
            for pixel in pixels[::100]:  # Sample every 100th pixel
                color_hex = f"#{pixel[0]:02x}{pixel[1]:02x}{pixel[2]:02x}"
                if color_hex not in unique_colors and len(unique_colors) < 5:
                    unique_colors.append(color_hex)
            
            return unique_colors
            
        except Exception as e:
            self.logger.error(f"Error extracting colors: {e}")
            return []
    
    async def _analyze_composition(self, image: Image) -> str:
        """Analyze image composition type"""
        try:
            width, height = image.size
            aspect_ratio = width / height
            
            # Simple composition analysis
            if aspect_ratio > 1.5:
                return "landscape"
            elif aspect_ratio < 0.7:
                return "portrait"
            else:
                return "square"

        except (ZeroDivisionError, AttributeError):
            return "unknown"
    
    async def _detect_objects(self, image: Image) -> List[str]:
        """Detect objects in image using OpenAI Vision API or fallback heuristics"""
        detected_objects = []
        width, height = image.size

        # Try OpenAI Vision API if available
        api_key = os.environ.get('OPENAI_API_KEY')
        if api_key:
            try:
                import base64
                from io import BytesIO

                # Convert image to base64
                buffered = BytesIO()
                image.save(buffered, format="PNG")
                img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

                client = openai.OpenAI(api_key=api_key)
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "List the main objects and elements visible in this image. Return only a comma-separated list of object names, nothing else."},
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_base64}"}}
                            ]
                        }
                    ],
                    max_tokens=100
                )

                # Parse response into list
                objects_text = response.choices[0].message.content.strip()
                detected_objects = [obj.strip().lower() for obj in objects_text.split(',') if obj.strip()]
                self.logger.info(f"Vision API detected: {detected_objects}")
                return detected_objects

            except Exception as e:
                self.logger.debug(f"Vision API unavailable, using heuristics: {e}")

        # Fallback to heuristics when API unavailable
        file_size = len(image.tobytes()) if hasattr(image, 'tobytes') else 0

        if width > 800 and height > 800:
            detected_objects.append("high_resolution_content")
        if file_size > 1000000:
            detected_objects.append("detailed_imagery")
        if width > height * 1.5:
            detected_objects.append("landscape_format")
        elif height > width * 1.5:
            detected_objects.append("portrait_format")

        return detected_objects
    
    async def _ai_content_analysis(self, image: Image, variant_file: Path) -> Dict[str, Any]:
        """AI-powered content analysis using OpenAI Vision API"""
        api_key = os.environ.get('OPENAI_API_KEY')

        if api_key:
            try:
                import base64
                from io import BytesIO

                # Convert image to base64
                buffered = BytesIO()
                image.save(buffered, format="PNG")
                img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

                client = openai.OpenAI(api_key=api_key)
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": """Analyze this marketing creative image. Return a JSON object with:
1. "relevance_score": 0.0-1.0 rating of how effective it is as a marketing image
2. "text_elements": list of any text visible in the image
3. "suggestions": list of 2-3 specific improvements for better marketing impact
4. "brand_alignment": assessment of professional quality
5. "target_audience": who this image would appeal to

Return only valid JSON, no other text."""},
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_base64}"}}
                            ]
                        }
                    ],
                    max_tokens=300
                )

                # Parse JSON response
                response_text = response.choices[0].message.content.strip()
                # Handle markdown code blocks
                if response_text.startswith('```'):
                    response_text = response_text.split('```')[1]
                    if response_text.startswith('json'):
                        response_text = response_text[4:]

                analysis = json.loads(response_text)
                self.logger.info(f"AI analysis complete for {variant_file.name}")
                return analysis

            except json.JSONDecodeError as e:
                self.logger.warning(f"Failed to parse AI response: {e}")
            except Exception as e:
                self.logger.debug(f"Vision API unavailable for analysis: {e}")

        # Fallback analysis when API unavailable
        return {
            "relevance_score": 0.75,
            "text_elements": [],
            "suggestions": [
                "Ensure text is readable at all sizes",
                "Verify brand colors are consistent",
                "Check image resolution for all platforms"
            ],
            "brand_alignment": "Unable to analyze - API not configured",
            "target_audience": "General audience"
        }
    
    async def _detect_issues(self, analysis: VariantAnalysis) -> List[str]:
        """Detect potential issues with the variant"""
        issues = []
        
        # Quality issues
        if analysis.technical_quality < self.config["quality_threshold"]:
            issues.append("Low technical quality")
        
        # Resolution issues
        if analysis.resolution[0] < 800 or analysis.resolution[1] < 800:
            issues.append("Low resolution")
        
        # Brand compliance issues
        if not analysis.brand_colors_present:
            issues.append("Brand colors not detected")
        
        if analysis.brand_alignment < self.config["brand_compliance_threshold"]:
            issues.append("Poor brand alignment")
        
        # File size issues
        if analysis.file_size > 5 * 1024 * 1024:  # > 5MB
            issues.append("File size too large")
        elif analysis.file_size < 50 * 1024:  # < 50KB
            issues.append("File size suspiciously small")
        
        return issues


class QualityAnalyzer:
    """Advanced quality analysis for variants"""
    
    async def analyze_technical_quality(self, image: Image) -> float:
        """Analyze technical quality of image"""
        try:
            # Convert to OpenCV format for analysis
            img_array = np.array(image)
            
            # Calculate sharpness using Laplacian variance
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) if len(img_array.shape) == 3 else img_array
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # Normalize sharpness score
            sharpness_score = min(sharpness / 1000, 1.0)
            
            # Calculate noise level (simplified)
            noise_score = 1.0 - min(np.std(gray) / 128, 1.0)
            
            # Combine metrics
            technical_score = (sharpness_score * 0.6 + noise_score * 0.4)
            
            return min(max(technical_score, 0.0), 1.0)
            
        except Exception as e:
            logging.getLogger(__name__).error(f"Technical quality analysis failed: {e}")
            return 0.5
    
    async def analyze_aesthetic_quality(self, image: Image) -> float:
        """Analyze aesthetic quality (placeholder for advanced models)"""
        try:
            # This would integrate with aesthetic quality models
            # For now, using simple heuristics
            
            width, height = image.size
            aspect_ratio = width / height
            
            # Prefer common aspect ratios
            common_ratios = [1.0, 16/9, 9/16, 4/3, 3/4]
            ratio_score = max([1 - abs(aspect_ratio - ratio) for ratio in common_ratios])
            
            # Prefer higher resolutions
            resolution_score = min((width * height) / (1920 * 1080), 1.0)
            
            aesthetic_score = (ratio_score * 0.4 + resolution_score * 0.6)

            return min(max(aesthetic_score, 0.0), 1.0)

        except (ValueError, TypeError, ZeroDivisionError, AttributeError):
            return 0.5


class DiversityAnalyzer:
    """Advanced diversity analysis for variant collections"""
    
    async def calculate_diversity_index(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate overall diversity index"""
        if not analyses:
            return 0.0
        
        # Combine multiple diversity factors
        color_div = await self.calculate_color_diversity(analyses)
        composition_div = await self.calculate_composition_diversity(analyses)
        content_div = await self.calculate_content_diversity(analyses)
        
        return (color_div + composition_div + content_div) / 3
    
    async def calculate_style_variety(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate style variety score"""
        if not analyses:
            return 0.0
        
        # Count unique composition types
        composition_types = set(analysis.composition_type for analysis in analyses)
        
        # Count unique aspect ratios
        aspect_ratios = set(analysis.aspect_ratio for analysis in analyses)
        
        # Calculate variety score
        variety_score = (len(composition_types) + len(aspect_ratios)) / (2 * len(analyses))
        
        return min(variety_score, 1.0)
    
    async def calculate_color_diversity(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate color diversity across variants"""
        if not analyses:
            return 0.0
        
        all_colors = set()
        for analysis in analyses:
            all_colors.update(analysis.dominant_colors)
        
        # Diversity based on unique colors vs total variants
        diversity_score = len(all_colors) / (len(analyses) * 5)  # Assume max 5 colors per variant
        
        return min(diversity_score, 1.0)
    
    async def calculate_composition_diversity(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate composition diversity"""
        if not analyses:
            return 0.0
        
        composition_types = [analysis.composition_type for analysis in analyses]
        unique_compositions = set(composition_types)
        
        diversity_score = len(unique_compositions) / len(analyses)
        
        return min(diversity_score, 1.0)
    
    async def calculate_content_diversity(self, analyses: List[VariantAnalysis]) -> float:
        """Calculate content diversity based on detected objects and elements"""
        if not analyses:
            return 0.0
        
        all_objects = set()
        for analysis in analyses:
            all_objects.update(analysis.object_detection)
            all_objects.update(analysis.text_elements)
        
        diversity_score = len(all_objects) / len(analyses)
        
        return min(diversity_score, 1.0)


class BrandComplianceAnalyzer:
    """Brand compliance analysis and guideline validation"""
    
    async def analyze_compliance(self, image: Image, campaign_id: str) -> Dict[str, Any]:
        """Analyze brand compliance for an image"""
        
        # This would integrate with brand guideline databases
        # For now, using simplified analysis
        
        results = {
            "alignment_score": 0.8,
            "colors_compliant": True,
            "logo_detected": False,
            "font_compliant": True,
            "style_compliant": True,
            "violations": []
        }
        
        # Load brand guidelines for campaign (placeholder)
        brand_guidelines = await self._load_brand_guidelines(campaign_id)
        
        # Analyze brand colors
        results["colors_compliant"] = await self._check_brand_colors(image, brand_guidelines)
        
        # Check for logo presence
        results["logo_detected"] = await self._detect_logo(image, brand_guidelines)
        
        return results
    
    async def _load_brand_guidelines(self, campaign_id: str) -> Dict[str, Any]:
        """Load brand guidelines for campaign from file or return defaults"""
        import json
        import yaml
        from pathlib import Path

        # Try to load from campaign-specific guidelines file
        guidelines_paths = [
            Path(f"campaigns/{campaign_id}/brand_guidelines.json"),
            Path(f"campaigns/{campaign_id}/brand_guidelines.yaml"),
            Path(f"assets/brand_guidelines.json"),
            Path(f"assets/brand_guidelines.yaml"),
            Path("brand_guidelines.json"),
            Path("brand_guidelines.yaml")
        ]

        for path in guidelines_paths:
            if path.exists():
                try:
                    with open(path, 'r') as f:
                        if path.suffix == '.json':
                            return json.load(f)
                        else:
                            return yaml.safe_load(f)
                except Exception as e:
                    logging.getLogger(__name__).warning(f"Failed to load guidelines from {path}: {e}")

        # Default brand guidelines
        return {
            "colors": ["#000000", "#FFFFFF", "#0066CC"],
            "fonts": ["Arial", "Helvetica", "sans-serif"],
            "logo_required": False,
            "style_elements": ["professional", "clean"],
            "color_tolerance": 30  # RGB tolerance for color matching
        }

    async def _check_brand_colors(self, image: Image, guidelines: Dict[str, Any]) -> bool:
        """Check if brand colors are present in the image"""
        try:
            # Get brand colors from guidelines
            brand_colors = guidelines.get("colors", [])
            if not brand_colors:
                return True

            # Convert brand colors to RGB
            brand_rgb = []
            for color in brand_colors:
                if isinstance(color, str) and color.startswith('#'):
                    # Hex color
                    hex_color = color.lstrip('#')
                    brand_rgb.append(tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4)))
                elif isinstance(color, (list, tuple)) and len(color) >= 3:
                    brand_rgb.append(tuple(color[:3]))

            if not brand_rgb:
                return True

            # Sample image colors
            img_rgb = image.convert('RGB').resize((50, 50))
            pixels = list(img_rgb.getdata())

            # Check if any brand colors are present (with tolerance)
            tolerance = guidelines.get("color_tolerance", 30)
            colors_found = 0

            for brand_color in brand_rgb:
                for pixel in pixels:
                    if all(abs(brand_color[i] - pixel[i]) <= tolerance for i in range(3)):
                        colors_found += 1
                        break

            # At least 50% of brand colors should be present
            return colors_found >= len(brand_rgb) / 2

        except Exception as e:
            logging.getLogger(__name__).warning(f"Brand color check failed: {e}")
            return True

    async def _detect_logo(self, image: Image, guidelines: Dict[str, Any]) -> bool:
        """Detect if a logo area exists in the image (basic detection)"""
        try:
            # If logo is not required, skip detection
            if not guidelines.get("logo_required", False):
                return True  # Consider it compliant if not required

            # Check if logo file exists in project
            from pathlib import Path
            logo_paths = [
                Path("assets/logo.png"),
                Path("assets/logo.jpg"),
                Path("assets/logos/logo.png"),
                Path("logo.png")
            ]

            logo_exists = any(p.exists() for p in logo_paths)
            if not logo_exists:
                return True  # No logo to detect

            # Basic detection: look for a distinct region in corners
            # (where logos are typically placed)
            img_small = image.convert('RGB').resize((100, 100))
            pixels = list(img_small.getdata())

            # Check corners for distinct patterns (logo indicator)
            corners = [
                pixels[:10],  # Top-left
                pixels[90:100],  # Top-right
                pixels[-100:-90],  # Bottom-left
                pixels[-10:]  # Bottom-right
            ]

            # Look for low variance region (potential logo)
            for corner in corners:
                if len(set(corner)) < 3:  # Very uniform = potential logo
                    return True

            # Without ML models, assume logo might be present
            return True

        except Exception as e:
            logging.getLogger(__name__).warning(f"Logo detection failed: {e}")
            return False


class PerformanceTracker:
    """Track performance metrics for variant generation"""
    
    def __init__(self):
        self.generation_times = []
        self.success_rates = {}
        self.cost_tracking = {}
    
    def track_generation_time(self, variant_id: str, generation_time: float):
        """Track generation time for a variant"""
        self.generation_times.append({
            "variant_id": variant_id,
            "time": generation_time,
            "timestamp": datetime.now()
        })
    
    def calculate_average_generation_time(self, campaign_id: str) -> float:
        """Calculate average generation time for campaign"""
        campaign_times = [
            entry["time"] for entry in self.generation_times
            if entry["variant_id"].startswith(campaign_id)
        ]
        
        return np.mean(campaign_times) if campaign_times else 0.0


class EngagementPredictor:
    """Predict engagement potential for variants"""
    
    async def predict_engagement(self, analyses: List[VariantAnalysis]) -> Dict[str, float]:
        """Predict engagement metrics for variants"""
        
        predictions = {
            "click_through_rate": 0.0,
            "conversion_rate": 0.0,
            "engagement_score": 0.0,
            "viral_potential": 0.0
        }
        
        if not analyses:
            return predictions
        
        # Calculate predictions based on quality and diversity
        avg_quality = np.mean([a.technical_quality for a in analyses if a.technical_quality > 0])
        
        # Simple prediction model (would use ML in production)
        predictions["click_through_rate"] = min(avg_quality * 0.05, 0.1)
        predictions["conversion_rate"] = min(avg_quality * 0.02, 0.05)
        predictions["engagement_score"] = avg_quality
        predictions["viral_potential"] = avg_quality * 0.3
        
        return predictions
    
    async def generate_ab_test_recommendations(self, analyses: List[VariantAnalysis]) -> List[str]:
        """Generate A/B testing recommendations"""
        
        recommendations = []
        
        if len(analyses) >= 2:
            recommendations.append("Test top 2 performing variants for CTR optimization")
        
        if len(set(a.composition_type for a in analyses)) > 1:
            recommendations.append("A/B test different composition styles")
        
        if len(set(a.aspect_ratio for a in analyses)) > 1:
            recommendations.append("Compare performance across aspect ratios")
        
        return recommendations


# Example usage and demo
async def demo_variant_intelligence():
    """Demonstrate the variant intelligence system"""
    engine = VariantIntelligenceEngine()
    
    print("üé® AI-Powered Variant Intelligence System Demo")
    print("=" * 50)
    print("üìä Advanced Features:")
    print("  ‚úÖ AI-powered quality analysis and scoring")
    print("  ‚úÖ Comprehensive diversity and variety metrics")
    print("  ‚úÖ Brand compliance and guideline validation")
    print("  ‚úÖ Performance tracking and optimization insights")
    print("  ‚úÖ Engagement prediction and A/B test recommendations")
    print("  ‚úÖ Real-time duplicate detection and issue identification")
    
    # Simulate variant tracking
    output_dir = Path("output")
    campaign_id = "demo_campaign"
    
    print(f"\nüîç Analyzing variants for campaign: {campaign_id}")
    
    # This would analyze real variants in production
    metrics = await engine.track_campaign_variants(campaign_id, output_dir)
    
    print(f"üìà Analysis Results:")
    print(f"  Total Variants: {metrics.total_count}")
    print(f"  Quality Score: {metrics.avg_quality_score:.2f}")
    print(f"  Diversity Index: {metrics.diversity_index:.2f}")
    print(f"  Brand Compliance: {metrics.brand_compliance_rate:.2f}")
    
    return engine


if __name__ == "__main__":
    asyncio.run(demo_variant_intelligence())