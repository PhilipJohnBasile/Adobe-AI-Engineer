"""
Real-Time Creative Performance Prediction System

Uses machine learning to predict campaign performance metrics like CTR, conversion rates,
and engagement scores based on creative elements and campaign characteristics.

Free technologies used:
- scikit-learn for ML models
- pandas/numpy for data processing
- PIL/OpenCV for image analysis
- matplotlib for visualization
"""

import logging
import json
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
import pickle
import cv2
from PIL import Image, ImageStat
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score
import joblib

logger = logging.getLogger(__name__)


class CreativeFeatureExtractor:
    """Extract features from creative assets for ML prediction."""
    
    def __init__(self):
        self.supported_formats = {'.jpg', '.jpeg', '.png', '.webp', '.bmp'}
    
    def extract_visual_features(self, image_path: str) -> Dict[str, float]:
        """Extract visual features from an image."""
        try:
            # Load image
            img = cv2.imread(image_path)
            if img is None:
                logger.warning(f"Could not load image: {image_path}")
                return self._get_default_features()
            
            # Convert to RGB
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(img_rgb)
            
            features = {}
            
            # Basic image properties
            height, width = img.shape[:2]
            features['width'] = width
            features['height'] = height
            features['aspect_ratio'] = width / height if height > 0 else 1.0
            features['total_pixels'] = width * height
            
            # Color analysis
            stat = ImageStat.Stat(pil_img)
            features['mean_red'] = stat.mean[0] / 255.0
            features['mean_green'] = stat.mean[1] / 255.0
            features['mean_blue'] = stat.mean[2] / 255.0
            features['brightness'] = sum(stat.mean) / (3 * 255.0)
            
            # Color variance (indicates color diversity)
            features['color_variance'] = np.var(stat.mean) / (255.0 ** 2)
            
            # Edge detection (indicates visual complexity)
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            features['edge_density'] = np.sum(edges > 0) / (width * height)
            
            # Contrast analysis
            features['contrast'] = gray.std() / 255.0
            
            # Color histogram features
            hist_r = cv2.calcHist([img_rgb], [0], None, [8], [0, 256])
            hist_g = cv2.calcHist([img_rgb], [1], None, [8], [0, 256])
            hist_b = cv2.calcHist([img_rgb], [2], None, [8], [0, 256])
            
            # Dominant color features
            features['dominant_red'] = np.argmax(hist_r) / 7.0
            features['dominant_green'] = np.argmax(hist_g) / 7.0
            features['dominant_blue'] = np.argmax(hist_b) / 7.0
            
            # Color distribution entropy
            total_pixels = width * height
            hist_normalized = np.concatenate([hist_r, hist_g, hist_b]) / total_pixels
            hist_normalized = hist_normalized[hist_normalized > 0]
            features['color_entropy'] = -np.sum(hist_normalized * np.log2(hist_normalized))
            
            return features
            
        except Exception as e:
            logger.warning(f"Error extracting features from {image_path}: {e}")
            return self._get_default_features()
    
    def _get_default_features(self) -> Dict[str, float]:
        """Return default features when image analysis fails."""
        return {
            'width': 512, 'height': 512, 'aspect_ratio': 1.0, 'total_pixels': 262144,
            'mean_red': 0.5, 'mean_green': 0.5, 'mean_blue': 0.5, 'brightness': 0.5,
            'color_variance': 0.1, 'edge_density': 0.1, 'contrast': 0.5,
            'dominant_red': 0.5, 'dominant_green': 0.5, 'dominant_blue': 0.5,
            'color_entropy': 3.0
        }


class PerformancePredictionModel:
    """ML model for predicting creative performance."""
    
    def __init__(self, model_dir: str = "models"):
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(exist_ok=True)
        
        self.feature_extractor = CreativeFeatureExtractor()
        self.models = {
            'ctr': None,
            'conversion_rate': None,
            'engagement_score': None,
            'brand_recall': None
        }
        self.scalers = {}
        self.label_encoders = {}
        
        # Load existing models if available
        self._load_models()
        
        # Generate synthetic training data if no models exist
        if not any(self.models.values()):
            self._generate_training_data()
            self._train_models()
    
    def _load_models(self):
        """Load pre-trained models if they exist."""
        for metric in self.models.keys():
            model_path = self.model_dir / f"{metric}_model.joblib"
            scaler_path = self.model_dir / f"{metric}_scaler.joblib"
            
            if model_path.exists() and scaler_path.exists():
                try:
                    self.models[metric] = joblib.load(model_path)
                    self.scalers[metric] = joblib.load(scaler_path)
                    logger.info(f"Loaded {metric} model from {model_path}")
                except Exception as e:
                    logger.warning(f"Failed to load {metric} model: {e}")
    
    def _save_models(self):
        """Save trained models to disk."""
        for metric in self.models.keys():
            if self.models[metric] is not None:
                model_path = self.model_dir / f"{metric}_model.joblib"
                scaler_path = self.model_dir / f"{metric}_scaler.joblib"
                
                try:
                    joblib.dump(self.models[metric], model_path)
                    joblib.dump(self.scalers[metric], scaler_path)
                    logger.info(f"Saved {metric} model to {model_path}")
                except Exception as e:
                    logger.warning(f"Failed to save {metric} model: {e}")
    
    def _generate_training_data(self, n_samples: int = 1000):
        """Generate synthetic training data based on creative performance patterns."""
        logger.info("Generating synthetic training data for performance prediction...")
        
        np.random.seed(42)  # For reproducible results
        
        # Generate synthetic creative features
        data = []
        for i in range(n_samples):
            # Random image characteristics
            width = np.random.choice([512, 768, 1024, 1080, 1200])
            height = np.random.choice([512, 768, 1024, 1080, 1200])
            aspect_ratio = width / height
            
            # Color features
            brightness = np.random.uniform(0.2, 0.9)
            contrast = np.random.uniform(0.3, 0.8)
            color_variance = np.random.uniform(0.05, 0.3)
            edge_density = np.random.uniform(0.05, 0.25)
            
            # Campaign features
            market = np.random.choice(['US', 'UK', 'DE', 'JP', 'FR'])
            audience_age = np.random.choice(['18-25', '26-35', '36-45', '46-55', '55+'])
            product_category = np.random.choice(['Tech', 'Fashion', 'Food', 'Beauty', 'Fitness'])
            campaign_budget = np.random.uniform(1000, 50000)
            
            # Message features
            message_length = np.random.randint(10, 100)
            has_cta = np.random.choice([0, 1])
            has_emoji = np.random.choice([0, 1])
            
            # Calculate performance based on realistic patterns
            # CTR influenced by visual appeal and targeting
            visual_appeal = 0.3 * (1 - abs(aspect_ratio - 1.0)) + 0.2 * contrast + 0.2 * edge_density + 0.3 * brightness
            targeting_factor = 1.0 + (0.2 if audience_age in ['26-35', '36-45'] else 0)
            ctr = np.clip(0.5 + visual_appeal * targeting_factor + np.random.normal(0, 0.2), 0.1, 5.0)
            
            # Conversion rate influenced by CTA and brand elements
            conversion_factor = 1.5 if has_cta else 1.0
            brand_factor = 1.2 if product_category in ['Tech', 'Beauty'] else 1.0
            conversion_rate = np.clip(ctr * 0.1 * conversion_factor * brand_factor + np.random.normal(0, 0.05), 0.01, 0.5)
            
            # Engagement score influenced by visual complexity and market
            market_factor = {'US': 1.0, 'UK': 0.9, 'DE': 0.8, 'JP': 1.1, 'FR': 0.95}[market]
            engagement_score = np.clip(visual_appeal * 2 * market_factor + np.random.normal(0, 0.3), 0.5, 5.0)
            
            # Brand recall influenced by contrast and consistency
            brand_recall = np.clip(contrast * 2 + 0.5 + np.random.normal(0, 0.2), 0.3, 1.0)
            
            sample = {
                'width': width, 'height': height, 'aspect_ratio': aspect_ratio,
                'brightness': brightness, 'contrast': contrast, 'color_variance': color_variance,
                'edge_density': edge_density, 'market': market, 'audience_age': audience_age,
                'product_category': product_category, 'campaign_budget': campaign_budget,
                'message_length': message_length, 'has_cta': has_cta, 'has_emoji': has_emoji,
                'ctr': ctr, 'conversion_rate': conversion_rate, 'engagement_score': engagement_score,
                'brand_recall': brand_recall
            }
            data.append(sample)
        
        self.training_data = pd.DataFrame(data)
        logger.info(f"Generated {n_samples} synthetic training samples")
    
    def _train_models(self):
        """Train ML models for each performance metric."""
        logger.info("Training performance prediction models...")
        
        # Prepare features
        categorical_features = ['market', 'audience_age', 'product_category']
        for feature in categorical_features:
            if feature not in self.label_encoders:
                self.label_encoders[feature] = LabelEncoder()
                self.training_data[f'{feature}_encoded'] = self.label_encoders[feature].fit_transform(self.training_data[feature])
        
        # Feature columns
        feature_columns = [
            'width', 'height', 'aspect_ratio', 'brightness', 'contrast', 'color_variance',
            'edge_density', 'campaign_budget', 'message_length', 'has_cta', 'has_emoji',
            'market_encoded', 'audience_age_encoded', 'product_category_encoded'
        ]
        
        X = self.training_data[feature_columns]
        
        # Train models for each metric
        for metric in ['ctr', 'conversion_rate', 'engagement_score', 'brand_recall']:
            y = self.training_data[metric]
            
            # Scale features
            self.scalers[metric] = StandardScaler()
            X_scaled = self.scalers[metric].fit_transform(X)
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
            
            # Train model (using Gradient Boosting for better performance)
            model = GradientBoostingRegressor(n_estimators=100, random_state=42)
            model.fit(X_train, y_train)
            
            # Evaluate
            y_pred = model.predict(X_test)
            r2 = r2_score(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            
            logger.info(f"{metric} model - RÂ²: {r2:.3f}, RMSE: {rmse:.3f}")
            
            self.models[metric] = model
        
        # Save models
        self._save_models()
        logger.info("Model training completed")
    
    def predict_performance(self, image_path: str = None, campaign_brief: Dict = None) -> Dict[str, float]:
        """Predict performance metrics for a creative."""
        if not any(self.models.values()):
            logger.warning("No trained models available")
            return self._get_default_predictions()
        
        try:
            # Extract visual features
            if image_path and Path(image_path).exists():
                visual_features = self.feature_extractor.extract_visual_features(image_path)
            else:
                visual_features = self.feature_extractor._get_default_features()
            
            # Extract campaign features
            campaign_features = self._extract_campaign_features(campaign_brief or {})
            
            # Combine features
            all_features = {**visual_features, **campaign_features}
            
            # Prepare feature vector
            feature_vector = self._prepare_feature_vector(all_features)
            
            # Predict each metric
            predictions = {}
            for metric in self.models.keys():
                if self.models[metric] is not None and self.scalers[metric] is not None:
                    X_scaled = self.scalers[metric].transform([feature_vector])
                    prediction = self.models[metric].predict(X_scaled)[0]
                    predictions[metric] = max(0, prediction)  # Ensure non-negative
                else:
                    predictions[metric] = self._get_default_predictions()[metric]
            
            return predictions
            
        except Exception as e:
            logger.error(f"Error predicting performance: {e}")
            return self._get_default_predictions()
    
    def _extract_campaign_features(self, campaign_brief: Dict) -> Dict[str, Any]:
        """Extract features from campaign brief."""
        features = {}
        
        # Market
        markets = campaign_brief.get('markets', ['US'])
        features['market'] = markets[0] if markets else 'US'
        
        # Audience (simplified)
        target_audience = campaign_brief.get('target_audience', '26-35')
        if '18-25' in target_audience or 'young' in target_audience.lower():
            features['audience_age'] = '18-25'
        elif '26-35' in target_audience:
            features['audience_age'] = '26-35'
        elif '36-45' in target_audience:
            features['audience_age'] = '36-45'
        elif '46-55' in target_audience:
            features['audience_age'] = '46-55'
        else:
            features['audience_age'] = '26-35'  # Default
        
        # Product category
        products = campaign_brief.get('products', [])
        if products:
            category = products[0].get('category', 'Tech')
            if any(word in category.lower() for word in ['tech', 'electronics', 'gadget']):
                features['product_category'] = 'Tech'
            elif any(word in category.lower() for word in ['fashion', 'clothing', 'apparel']):
                features['product_category'] = 'Fashion'
            elif any(word in category.lower() for word in ['food', 'beverage', 'restaurant']):
                features['product_category'] = 'Food'
            elif any(word in category.lower() for word in ['beauty', 'cosmetic', 'skincare']):
                features['product_category'] = 'Beauty'
            elif any(word in category.lower() for word in ['fitness', 'health', 'wellness']):
                features['product_category'] = 'Fitness'
            else:
                features['product_category'] = 'Tech'  # Default
        else:
            features['product_category'] = 'Tech'
        
        # Budget (simplified)
        budget_str = campaign_brief.get('budget', '$10,000')
        try:
            budget = float(budget_str.replace('$', '').replace(',', ''))
        except:
            budget = 10000.0
        features['campaign_budget'] = budget
        
        # Message features
        messaging = campaign_brief.get('creative_requirements', {}).get('messaging', {})
        primary_message = messaging.get('primary', '')
        call_to_action = messaging.get('call_to_action', '')
        
        features['message_length'] = len(primary_message) if primary_message else 50
        features['has_cta'] = 1 if call_to_action else 0
        features['has_emoji'] = 1 if any(char in primary_message + call_to_action for char in 'ðŸ˜ŠðŸŽ‰ðŸ‘âœ¨ðŸ”¥ðŸ’¯') else 0
        
        return features
    
    def _prepare_feature_vector(self, features: Dict) -> List[float]:
        """Prepare feature vector for model prediction."""
        # Encode categorical features
        encoded_features = dict(features)
        
        categorical_features = ['market', 'audience_age', 'product_category']
        for feature in categorical_features:
            if feature in self.label_encoders:
                try:
                    value = encoded_features.get(feature, 'US' if feature == 'market' else ('26-35' if feature == 'audience_age' else 'Tech'))
                    encoded_features[f'{feature}_encoded'] = self.label_encoders[feature].transform([value])[0]
                except:
                    # Handle unknown categories
                    encoded_features[f'{feature}_encoded'] = 0
            else:
                encoded_features[f'{feature}_encoded'] = 0
        
        # Feature order (must match training data)
        feature_order = [
            'width', 'height', 'aspect_ratio', 'brightness', 'contrast', 'color_variance',
            'edge_density', 'campaign_budget', 'message_length', 'has_cta', 'has_emoji',
            'market_encoded', 'audience_age_encoded', 'product_category_encoded'
        ]
        
        return [encoded_features.get(feature, 0.0) for feature in feature_order]
    
    def _get_default_predictions(self) -> Dict[str, float]:
        """Return default predictions when model fails."""
        return {
            'ctr': 1.2,
            'conversion_rate': 0.08,
            'engagement_score': 2.5,
            'brand_recall': 0.65
        }
    
    def get_optimization_suggestions(self, predictions: Dict[str, float]) -> List[str]:
        """Generate optimization suggestions based on predictions."""
        suggestions = []
        
        if predictions['ctr'] < 1.0:
            suggestions.append("CTR prediction is low. Consider using more contrasting colors and clear visual hierarchy.")
        
        if predictions['conversion_rate'] < 0.05:
            suggestions.append("Conversion rate could be improved. Add a clear call-to-action and value proposition.")
        
        if predictions['engagement_score'] < 2.0:
            suggestions.append("Engagement score is low. Consider more visually appealing elements and emotional messaging.")
        
        if predictions['brand_recall'] < 0.5:
            suggestions.append("Brand recall needs improvement. Ensure brand colors and logo are prominent.")
        
        if not suggestions:
            suggestions.append("Predictions look good! This creative should perform well.")
        
        return suggestions


class PerformancePredictionEngine:
    """Main engine for creative performance prediction."""
    
    def __init__(self):
        self.model = PerformancePredictionModel()
        self.prediction_history = []
    
    def predict_creative_performance(self, image_path: str = None, campaign_brief: Dict = None) -> Dict:
        """Predict performance for a creative asset."""
        logger.info(f"Predicting performance for creative: {image_path}")
        
        # Get predictions
        predictions = self.model.predict_performance(image_path, campaign_brief)
        
        # Get optimization suggestions
        suggestions = self.model.get_optimization_suggestions(predictions)
        
        # Calculate overall performance score (weighted average)
        weights = {'ctr': 0.3, 'conversion_rate': 0.4, 'engagement_score': 0.2, 'brand_recall': 0.1}
        normalized_scores = {
            'ctr': min(predictions['ctr'] / 3.0, 1.0),  # Normalize to 0-1
            'conversion_rate': min(predictions['conversion_rate'] / 0.2, 1.0),
            'engagement_score': min(predictions['engagement_score'] / 5.0, 1.0),
            'brand_recall': predictions['brand_recall']  # Already 0-1
        }
        overall_score = sum(weights[metric] * normalized_scores[metric] for metric in weights.keys())
        
        result = {
            'timestamp': datetime.now().isoformat(),
            'image_path': image_path,
            'predictions': predictions,
            'overall_score': overall_score,
            'performance_grade': self._get_performance_grade(overall_score),
            'optimization_suggestions': suggestions,
            'confidence': self._calculate_confidence(predictions)
        }
        
        # Store in history
        self.prediction_history.append(result)
        
        return result
    
    def _get_performance_grade(self, score: float) -> str:
        """Convert overall score to letter grade."""
        if score >= 0.9:
            return 'A+'
        elif score >= 0.8:
            return 'A'
        elif score >= 0.7:
            return 'B'
        elif score >= 0.6:
            return 'C'
        elif score >= 0.5:
            return 'D'
        else:
            return 'F'
    
    def _calculate_confidence(self, predictions: Dict[str, float]) -> float:
        """Calculate prediction confidence based on model performance."""
        # Simplified confidence calculation
        # In practice, this would use model uncertainty estimation
        return 0.75 + np.random.uniform(-0.1, 0.1)  # 65-85% confidence
    
    def get_performance_report(self) -> Dict:
        """Generate performance prediction report."""
        if not self.prediction_history:
            return {'message': 'No predictions available'}
        
        recent_predictions = self.prediction_history[-10:]  # Last 10 predictions
        
        # Calculate averages
        avg_scores = {}
        for metric in ['ctr', 'conversion_rate', 'engagement_score', 'brand_recall']:
            scores = [p['predictions'][metric] for p in recent_predictions]
            avg_scores[metric] = np.mean(scores)
        
        avg_overall = np.mean([p['overall_score'] for p in recent_predictions])
        avg_confidence = np.mean([p['confidence'] for p in recent_predictions])
        
        # Grade distribution
        grades = [p['performance_grade'] for p in recent_predictions]
        grade_counts = {grade: grades.count(grade) for grade in set(grades)}
        
        return {
            'total_predictions': len(self.prediction_history),
            'recent_predictions': len(recent_predictions),
            'average_scores': avg_scores,
            'average_overall_score': avg_overall,
            'average_confidence': avg_confidence,
            'grade_distribution': grade_counts,
            'top_performing_creative': max(recent_predictions, key=lambda x: x['overall_score'])['image_path'] if recent_predictions else None
        }
    
    def batch_predict(self, image_paths: List[str], campaign_brief: Dict = None) -> List[Dict]:
        """Predict performance for multiple creatives."""
        results = []
        for image_path in image_paths:
            result = self.predict_creative_performance(image_path, campaign_brief)
            results.append(result)
        
        # Sort by overall score
        results.sort(key=lambda x: x['overall_score'], reverse=True)
        
        logger.info(f"Batch prediction completed for {len(image_paths)} creatives")
        return results